{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9cf18-4a67-4975-a6c0-0b6b8e62c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.Cluster the publish time into 10-minute intervals (e.g. from 02:20 to 02:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec14ab4a-109d-4209-898a-04272981170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id trending_date  \\\n",
      "0  n1WpP7iowLc      17.14.11   \n",
      "1  0dBIkQ4Mz1M      17.14.11   \n",
      "2  5qpjK5DgCt4      17.14.11   \n",
      "3  d380meD0W0M      17.14.11   \n",
      "4  2Vv-BfVoq4g      17.14.11   \n",
      "\n",
      "                                               title channel_title  \\\n",
      "0         Eminem - Walk On Water (Audio) ft. BeyoncÃ©    EminemVEVO   \n",
      "1                      PLUSH - Bad Unboxing Fan Mail     iDubbbzTV   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...  Rudy Mancuso   \n",
      "3                           I Dare You: GOING BALD!?      nigahiga   \n",
      "4        Ed Sheeran - Perfect (Official Music Video)    Ed Sheeran   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           10  2017-11-10T17:00:03.000Z   \n",
      "1           23  2017-11-13T17:00:00.000Z   \n",
      "2           23  2017-11-12T19:05:24.000Z   \n",
      "3           24  2017-11-12T18:01:41.000Z   \n",
      "4           10  2017-11-09T11:04:14.000Z   \n",
      "\n",
      "                                                tags     views    likes  \\\n",
      "0  Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...  17158579   787425   \n",
      "1  plush|\"bad unboxing\"|\"unboxing\"|\"fan mail\"|\"id...   1014651   127794   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...   3191434   146035   \n",
      "3  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...   2095828   132239   \n",
      "4  edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...  33523622  1634130   \n",
      "\n",
      "   dislikes  comment_count                                  thumbnail_link  \\\n",
      "0     43420         125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
      "1      1688          13030  https://i.ytimg.com/vi/0dBIkQ4Mz1M/default.jpg   \n",
      "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "4     21082          85067  https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg   \n",
      "\n",
      "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0              False             False                   False   \n",
      "1              False             False                   False   \n",
      "2              False             False                   False   \n",
      "3              False             False                   False   \n",
      "4              False             False                   False   \n",
      "\n",
      "                                         description country  \n",
      "0  Eminem's new track Walk on Water ft. BeyoncÃ© i...  Canada  \n",
      "1  STill got a lot of packages. Probably will las...  Canada  \n",
      "2  WATCH MY PREVIOUS VIDEO â–¶ \\n\\nSUBSCRIBE â–º http...  Canada  \n",
      "3  I know it's been a while since we did this sho...  Canada  \n",
      "4  ðŸŽ§: https://ad.gt/yt-perfect\\nðŸ’°: https://atlant...  Canada  \n"
     ]
    }
   ],
   "source": [
    "#to solve this question first I need to have the solution for question 1, that I have get the file from my teammate.\n",
    "#because the file was larger than 100MB we could not load it in the github.\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "final_df = pd.read_csv(r'C:\\Users\\Utente\\youtube\\data\\final_df.csv')\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc84a46-4fd7-4957-966e-e44fb4c65029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         publish_time interval_10min\n",
      "0 2017-11-10 17:00:03    17:00-17:10\n",
      "1 2017-11-13 17:00:00    17:00-17:10\n",
      "2 2017-11-12 19:05:24    19:00-19:10\n",
      "3 2017-11-12 18:01:41    18:00-18:10\n",
      "4 2017-11-09 11:04:14    11:00-11:10\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert the column to datetime objects\n",
    "final_df['publish_time'] = pd.to_datetime(final_df['publish_time'])\n",
    "#REMOVE the timezone (I checked it in the file, it was the same in all countries)\n",
    "final_df['publish_time'] = final_df['publish_time'].dt.tz_localize(None)\n",
    "\n",
    "# 2. Round down to the nearest 10 minutes\n",
    "# Example: 02:23:00 becomes 02:20:00\n",
    "interval_start = final_df['publish_time'].dt.floor('10min')\n",
    "\n",
    "# 3. Create your \"Start-End\" string format\n",
    "# Adds 10 minutes to the start time to get the end time\n",
    "final_df['interval_10min'] = (\n",
    "    interval_start.dt.strftime('%H:%M') + \"-\" + \n",
    "    (interval_start + pd.Timedelta(minutes=10)).dt.strftime('%H:%M')\n",
    ")\n",
    "\n",
    "print(final_df[['publish_time', 'interval_10min']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bb875-2e64-49c6-aea3-7d9f52970ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.For each interval, determine the number of videos, average number of likes and of dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23e7430-4e94-407a-b330-83800898eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  interval_10min  num_videos     avg_likes  avg_dislikes\n",
      "0    00:00-00:10        2913  60951.483350   3787.232750\n",
      "1    00:10-00:20        1522  22553.870565   1437.457293\n",
      "2    00:20-00:30        1248  21258.370192   1066.330128\n",
      "3    00:30-00:40        1625  36604.352000    949.439385\n",
      "4    00:40-00:50        1283  41770.614186   1889.012471\n"
     ]
    }
   ],
   "source": [
    "interval_stats = final_df.groupby('interval_10min').agg(\n",
    "    num_videos=('video_id', 'count'),\n",
    "    avg_likes=('likes', 'mean'),\n",
    "    avg_dislikes=('dislikes', 'mean')\n",
    ").reset_index() #to reset 'interval_10min' from being index (was converted by groupby) into a flat table\n",
    "print(interval_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53694c-64c2-4575-a819-d3b62dbb8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.For each tag, determine the number of videos. Notice that tags contains a string with several tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c64d156-784a-433f-b47e-7069104901fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " first 30 tags with the numbers of repeats:\n",
      "\n",
      "           tag  repeat_nums\n",
      "0       eminem          670\n",
      "1        shady          217\n",
      "2    aftermath          421\n",
      "3           on        10502\n",
      "4        water         1940\n",
      "5          rap         6935\n",
      "6   interscope          985\n",
      "7         walk          830\n",
      "8         best        13086\n",
      "9     unboxing         1940\n",
      "10   idubbbztv           42\n",
      "11    packages          131\n",
      "12        mail          165\n",
      "13         bad         3169\n",
      "14      things         2653\n",
      "15        chop          189\n",
      "16  idubbbztv2           33\n",
      "17       plush           24\n",
      "18    chontent            9\n",
      "19         fan         1020\n",
      "20    plushies           22\n",
      "21     license           52\n",
      "22        love         8336\n",
      "23      sarkis          583\n",
      "24     getting          568\n",
      "25      racist          296\n",
      "26      inanna          591\n",
      "27   pineapple          238\n",
      "28        rudy          446\n",
      "29      alesso          714\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "all_tags = []\n",
    "\n",
    "for tags_string in final_df['tags']:\n",
    "    if pd.notna(tags_string):  # Check if not NaN\n",
    "\n",
    "        # Lowercase so Funny = funny\n",
    "        clean_string = str(tags_string).lower()\n",
    "\n",
    "        # Split on ANY non-letter/number character. I detected any sepraters such as |, /, #, *... so I count all of them as sepraters\n",
    "        tags_list = re.split(r'[^a-z0-9]+', clean_string)\n",
    "\n",
    "        # Clean tags\n",
    "        tags_set = set()   # ensures one count per video\n",
    "        for tag in tags_list:\n",
    "            tag = tag.strip()\n",
    "            if tag and tag != '[none]' and tag != \"\":\n",
    "                tags_set.add(tag)\n",
    "\n",
    "        all_tags.extend(tags_set) #extend: add tags one by one\n",
    "\n",
    "# Count occurrences of each tag\n",
    "tag_counts = Counter(all_tags)\n",
    "#converting to a dataframe to print it\n",
    "tag_stats = pd.DataFrame(tag_counts.items(), columns=['tag', 'repeat_nums'])\n",
    "print(\"\\n first 30 tags with the numbers of repeats:\\n\")\n",
    "print(tag_stats.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0026c-1710-459f-9836-be8b30e1dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Find the tags with the largest number of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8f384af-fb6a-40ca-8b8a-5a0146970198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tag  repeat_nums\n",
      "2246    2018        43586\n",
      "134      the        43375\n",
      "804     none        37705\n",
      "50     video        31508\n",
      "432       tv        30323\n",
      "192      new        27643\n",
      "62     funny        24322\n",
      "982       de        23794\n",
      "94      news        23710\n",
      "72    comedy        22029\n",
      "866        a        21996\n",
      "49     music        21333\n",
      "45         s        21116\n",
      "284     show        20994\n",
      "299       of        19061\n",
      "162     2017        18421\n",
      "172       to        18035\n",
      "175       in        17357\n",
      "198   latest        16258\n",
      "537   videos        15513\n"
     ]
    }
   ],
   "source": [
    "tag_stats = tag_stats.sort_values('repeat_nums', ascending=False)\n",
    "print(tag_stats.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f79bd-3208-4c0c-8fe0-fc5b966ee71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. For each (tag, country) pair, compute average ratio likes/dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2487dd50-566b-4e79-8cae-a554b70a46fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         tag         country  avg_like/dislike_ratio\n",
      "317478              zydrunas         Germany               20.750000\n",
      "317479      zydrunassavickas         Germany              392.000000\n",
      "317480               zygarde          Canada              277.584615\n",
      "317481                zygote          Canada                7.550407\n",
      "317482                zygote         Germany                7.456664\n",
      "317483                zygote   United States                7.521840\n",
      "317484                zyklon         Germany               36.253186\n",
      "317485      zyklonabscheider         Germany               19.945946\n",
      "317486           zylberstein          France               17.000000\n",
      "317487              zylinder         Germany              159.251956\n",
      "317488          zylinderkopf         Germany               67.899178\n",
      "317489  zylinderkopfdichtung         Germany               60.764338\n",
      "317490      zylinderkopfriss         Germany               89.696023\n",
      "317491                 zylka   United States                0.979441\n",
      "317492                zymeri         Germany                5.491228\n",
      "317493                 zymni         Germany              399.333333\n",
      "317494                 zymny         Germany              262.338095\n",
      "317495                  zynk          Russia               18.423702\n",
      "317496              zypresse         Germany              166.000000\n",
      "317497              zyuohger           Japan               12.285714\n",
      "317498                 zyurt         Germany               29.523430\n",
      "317499                  zywo         Germany               16.102273\n",
      "317500                 zyx10           Japan               12.250000\n",
      "317501                 zyxel         Germany               25.583333\n",
      "317502                    zz          France               35.011208\n",
      "317503                    zz          Mexico               27.789217\n",
      "317504                   zzh          France                6.870451\n",
      "317505                   zzh         Germany                3.836959\n",
      "317506                zzr250           Japan               76.942761\n",
      "317507      zzzentertainment  United Kingdom              130.274495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_tags = final_df[['country', 'tags', 'likes', 'dislikes']].copy()\n",
    "\n",
    "# Clean & split tags\n",
    "df_tags['tags'] = (\n",
    "    df_tags['tags']\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.split(r'[^a-z0-9]+', regex=True)\n",
    ")\n",
    "\n",
    "# Explode\n",
    "df_exploded = df_tags.explode('tags')\n",
    "\n",
    "# Remove empty, [none], nan tags\n",
    "df_exploded = df_exploded[\n",
    "    (df_exploded['tags'] != \"\") &\n",
    "    (df_exploded['tags'] != \"[none]\") &\n",
    "    (df_exploded['tags'] != \"nan\") &\n",
    "    (df_exploded['tags'].str.contains('[a-z0-9]', regex=True))\n",
    "]\n",
    "\n",
    "\n",
    "# Avoid division by zero â†’ replace dislikes = 0 with 1 to calculate number of likes for those videos\n",
    "df_exploded['dislikes'] = df_exploded['dislikes'].replace(0, 1)\n",
    "df_exploded['ratio'] = df_exploded['likes'] / df_exploded['dislikes']\n",
    "\n",
    "# Group\n",
    "tag_country_stats = (\n",
    "    df_exploded.groupby(['tags', 'country'])['ratio']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'tags': 'tag', 'ratio': 'avg_like/dislike_ratio'})\n",
    ")\n",
    "\n",
    "print(tag_country_stats.tail(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
