{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4538f975-ae5e-4fc8-b16d-8630714e6193",
   "metadata": {},
   "source": [
    "# Foundations of Computer Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bc899-9575-4173-bb29-ac0a8f7f131e",
   "metadata": {},
   "source": [
    "Members of the Group : \n",
    "- Bahareh Robaty Shirzad (Student ID: 946887)\n",
    "- Samira Doshmankosh  (Student ID: \n",
    "- Setayesh Mohammadi Banadkooki (Student ID: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a29501-426d-45be-a45f-efe66aff1388",
   "metadata": {},
   "source": [
    "We have to work on the [Trending YouTube](https://drive.google.com/file/d/1VuI1NnPzYlhHIMBy-2nBegFoQTATbf8K/view?usp=sharing) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39814e2-caf9-410a-b5f9-c4dff8d2ba71",
   "metadata": {},
   "source": [
    "### Notes\n",
    "1. It is mandatory to use GitHub for developing the project.\n",
    "2. The project must be a jupyter notebook.\n",
    "3. There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "4. All questions on the project must be asked in the Discussion forum on the course website.\n",
    "5. At most 3 students can be in each group. You must create the groups by yourself. You can use the Discussion forum to create the groups.\n",
    "6. You do not have to send me the project before the discussion.\n",
    "7. You do not have to prepare any slides for the discussion.\n",
    "8. You can use AI tools, but you have to describe in the notebook how you have used such tools and you have to show that you have fully understood everything that you have in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f29ec7d4-cc03-487c-8bd1-6bb04a3daecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23393e0c-1ce7-46c4-989f-9feb87ff907e",
   "metadata": {},
   "source": [
    "## Question 1 : Create a single dataframe with the concatenation of all input csv files, adding a column called country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b4a9712-5039-4b4f-882c-df1eab038e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since in python synatx \\U means unicodeescape, by prefixing the string with an r behind the path, we will specify that-\n",
    "#-this is a raw string \n",
    "CAvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\CAvideos.csv.zst\"\n",
    "DEvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\DEvideos.csv.zst\"\n",
    "FRvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\FRvideos.csv.zst\"\n",
    "GBvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\GBvideos.csv.zst\"\n",
    "INvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\INvideos.csv.zst\"\n",
    "JPvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\JPvideos.csv.zst\"\n",
    "KRvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\KRvideos.csv.zst\"\n",
    "MXvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\MXvideos.csv.zst\"\n",
    "RUvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\RUvideos.csv.zst\"\n",
    "USvideos_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\\USvideos.csv.zst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5b14690-3025-4770-b79b-76a26e84eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(CAvideos_path)\n",
    "df2 = pd.read_csv(DEvideos_path)\n",
    "df3 = pd.read_csv(FRvideos_path)\n",
    "df4 = pd.read_csv(GBvideos_path)\n",
    "df5 = pd.read_csv(INvideos_path)\n",
    "df6 = pd.read_csv(JPvideos_path, encoding='utf-8', encoding_errors = \"replace\")\n",
    "df7 = pd.read_csv(KRvideos_path, encoding='utf-8', encoding_errors = \"replace\")\n",
    "df8 = pd.read_csv(MXvideos_path, encoding='utf-8', encoding_errors = \"replace\")\n",
    "df9 = pd.read_csv(RUvideos_path, encoding='utf-8', encoding_errors = \"replace\")\n",
    "df10 = pd.read_csv(USvideos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64c3a62c-d8d2-4c5e-a069-f7e6e83bf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'] = 'Canada'\n",
    "df2['country'] = 'Germany'\n",
    "df3['country'] = 'France'\n",
    "df4['country'] = 'United Kingdom'\n",
    "df5['country'] = 'India'\n",
    "df6['country'] = 'Japan'\n",
    "df7['country'] = 'South Korea'\n",
    "df8['country'] = 'Mexico'\n",
    "df9['country'] = 'Russia'\n",
    "df10['country'] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0114f4d5-8e8e-4899-a003-0f2f71af56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0b0b5c5-cb43-4cb0-ad44-d3a65180601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Eminem - Walk On Water (Audio) ft. Beyonc√©</td>\n",
       "      <td>EminemVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10T17:00:03.000Z</td>\n",
       "      <td>Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787425</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Eminem's new track Walk on Water ft. Beyonc√© i...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0dBIkQ4Mz1M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>PLUSH - Bad Unboxing Fan Mail</td>\n",
       "      <td>iDubbbzTV</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-13T17:00:00.000Z</td>\n",
       "      <td>plush|\"bad unboxing\"|\"unboxing\"|\"fan mail\"|\"id...</td>\n",
       "      <td>1014651</td>\n",
       "      <td>127794</td>\n",
       "      <td>1688</td>\n",
       "      <td>13030</td>\n",
       "      <td>https://i.ytimg.com/vi/0dBIkQ4Mz1M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>STill got a lot of packages. Probably will las...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146035</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ‚ñ∂ \\n\\nSUBSCRIBE ‚ñ∫ http...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095828</td>\n",
       "      <td>132239</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Vv-BfVoq4g</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Ed Sheeran - Perfect (Official Music Video)</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-09T11:04:14.000Z</td>\n",
       "      <td>edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...</td>\n",
       "      <td>33523622</td>\n",
       "      <td>1634130</td>\n",
       "      <td>21082</td>\n",
       "      <td>85067</td>\n",
       "      <td>https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>üéß: https://ad.gt/yt-perfect\\nüí∞: https://atlant...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  n1WpP7iowLc      17.14.11   \n",
       "1  0dBIkQ4Mz1M      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  d380meD0W0M      17.14.11   \n",
       "4  2Vv-BfVoq4g      17.14.11   \n",
       "\n",
       "                                               title channel_title  \\\n",
       "0         Eminem - Walk On Water (Audio) ft. Beyonc√©    EminemVEVO   \n",
       "1                      PLUSH - Bad Unboxing Fan Mail     iDubbbzTV   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...  Rudy Mancuso   \n",
       "3                           I Dare You: GOING BALD!?      nigahiga   \n",
       "4        Ed Sheeran - Perfect (Official Music Video)    Ed Sheeran   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           10  2017-11-10T17:00:03.000Z   \n",
       "1           23  2017-11-13T17:00:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-12T18:01:41.000Z   \n",
       "4           10  2017-11-09T11:04:14.000Z   \n",
       "\n",
       "                                                tags     views    likes  \\\n",
       "0  Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...  17158579   787425   \n",
       "1  plush|\"bad unboxing\"|\"unboxing\"|\"fan mail\"|\"id...   1014651   127794   \n",
       "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...   3191434   146035   \n",
       "3  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...   2095828   132239   \n",
       "4  edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...  33523622  1634130   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0     43420         125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
       "1      1688          13030  https://i.ytimg.com/vi/0dBIkQ4Mz1M/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "4     21082          85067  https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description country  \n",
       "0  Eminem's new track Walk on Water ft. Beyonc√© i...  Canada  \n",
       "1  STill got a lot of packages. Probably will las...  Canada  \n",
       "2  WATCH MY PREVIOUS VIDEO ‚ñ∂ \\n\\nSUBSCRIBE ‚ñ∫ http...  Canada  \n",
       "3  I know it's been a while since we did this sho...  Canada  \n",
       "4  üéß: https://ad.gt/yt-perfect\\nüí∞: https://atlant...  Canada  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d599fa-8a59-4a6f-b07e-75815d285cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4519eae4-ae37-4287-90d0-b4b454297c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id                  object\n",
      "trending_date             object\n",
      "title                     object\n",
      "channel_title             object\n",
      "category_id                int64\n",
      "publish_time              object\n",
      "tags                      object\n",
      "views                      int64\n",
      "likes                      int64\n",
      "dislikes                   int64\n",
      "comment_count              int64\n",
      "thumbnail_link            object\n",
      "comments_disabled           bool\n",
      "ratings_disabled            bool\n",
      "video_error_or_removed      bool\n",
      "description               object\n",
      "country                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79eb79-c4b7-46d8-b5d0-37febbc97f08",
   "metadata": {},
   "source": [
    "## Question 2 : Extract all videos that have no tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b102dcf-f2b2-47aa-8ddc-2a54bf695231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method: Using a lambda function to filter videos where the 'tags' column is '[none]'\n",
    "videos_with_no_tag = final_df[final_df['tags'].apply(lambda x: x == '[none]')]\n",
    "\n",
    "# Displaying the result\n",
    "videos_with_no_tag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3197e2-49ae-4d2d-a98e-4ee1f0481c6f",
   "metadata": {},
   "source": [
    "## Question 3: For each channel, determine the total number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f2302-79a3-40dd-9ca9-1aa266a1dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = list(set(final_df['channel_title']))\n",
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71765d2-cfde-458d-8d2c-60e803059f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "views = final_df.groupby('channel_title')['views'].sum()\n",
    "views.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21ac6e-09e2-42be-afb9-d1aaa58ecdc8",
   "metadata": {},
   "source": [
    "## 4. Save all rows with disabled comments and disabled ratings, or that have video_error_or_removed in a new dataframe called excluded, and remove those rows from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ff3a8-e91d-4941-92dc-c59fc425ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_condition = (\n",
    "    (final_df['comments_disabled'] == True) &  \n",
    "    (final_df['ratings_disabled'] == True)     \n",
    ") | (final_df['video_error_or_removed'] == True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bfbd9-df49-4a32-a610-7b6487c72746",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = final_df[exclusion_condition].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714e050-b9f1-4f02-8e33-8c6f8285e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_remove = excluded.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce5d97-14a5-41ce-85b5-3723a70a6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(rows_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ffaa4-34fa-47a8-8b80-d3e31711b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb6f2b-b298-47ba-a16c-3af8c22c5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows in 'excluded' DataFrame: {len(excluded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f86524-5de4-451f-88fc-82ffb5c6bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original Row Count (before exclusion): {len(excluded) + len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35099f-d1b4-47c1-b356-47130e50c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows remaining in 'final_df': {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e47a8-ec8b-4dbe-b14e-b4b2ca935e5d",
   "metadata": {},
   "source": [
    "## 5. Add a like_ratio column storing the ratio between the number of likes and dislikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96f2e7d7-36f7-4600-b246-f01dd4299dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For videos with zero dislikes, the ratio is undefined and therefore set to NaN.\n",
    "final_df['like_ratio'] = final_df.apply(\n",
    "    lambda r: r['likes'] / r['dislikes']\n",
    "    if pd.notna(r['dislikes']) and r['dislikes'] > 0\n",
    "    else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "final_df['no_dislikes'] = final_df['dislikes'].isna() | (final_df['dislikes'] == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f99d6569-c09e-47cc-93b1-211e0b800c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>like_ratio</th>\n",
       "      <th>no_dislikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787425</td>\n",
       "      <td>43420</td>\n",
       "      <td>18.135076</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127794</td>\n",
       "      <td>1688</td>\n",
       "      <td>75.707346</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146035</td>\n",
       "      <td>5339</td>\n",
       "      <td>27.352500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132239</td>\n",
       "      <td>1989</td>\n",
       "      <td>66.485168</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634130</td>\n",
       "      <td>21082</td>\n",
       "      <td>77.513044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes  dislikes  like_ratio  no_dislikes\n",
       "0   787425     43420   18.135076        False\n",
       "1   127794      1688   75.707346        False\n",
       "2   146035      5339   27.352500        False\n",
       "3   132239      1989   66.485168        False\n",
       "4  1634130     21082   77.513044        False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['likes', 'dislikes', 'like_ratio', 'no_dislikes']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c8a2050-155b-409d-b620-1d9670548787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>like_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes  dislikes  like_ratio\n",
       "67       0         0         NaN\n",
       "161    187         0         NaN\n",
       "173      0         0         NaN\n",
       "235     88         0         NaN\n",
       "271      1         0         NaN"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['no_dislikes'] == True][\n",
    "    ['likes', 'dislikes', 'like_ratio']\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1725b87-2340-404b-93da-a003b2f28cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\n",
    "    r\"C:\\Users\\broba\\Python-Project\\outputs\\final_df.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2af2fc-27f6-4a46-9679-5103099bba2c",
   "metadata": {},
   "source": [
    "## 6. Cluster the publish time into 10-minute intervals (e.g. from 02:20 to 02:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c760ad9-a0a3-4627-b9f1-3fc94a1ab6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         publish_time interval_10min\n",
      "0 2017-11-10 17:00:03    17:00-17:10\n",
      "1 2017-11-13 17:00:00    17:00-17:10\n",
      "2 2017-11-12 19:05:24    19:00-19:10\n",
      "3 2017-11-12 18:01:41    18:00-18:10\n",
      "4 2017-11-09 11:04:14    11:00-11:10\n"
     ]
    }
   ],
   "source": [
    "# Convert the column to datetime objects\n",
    "final_df['publish_time'] = pd.to_datetime(final_df['publish_time'])\n",
    "\n",
    "# remove the timezone (I checked it in the file, it was the same in all countries)\n",
    "final_df['publish_time'] = final_df['publish_time'].dt.tz_localize(None)\n",
    "\n",
    "# round down to the nearest 10 minutes. Example: 02:23:00 becomes 02:20:00\n",
    "interval_start = final_df['publish_time'].dt.floor('10min')\n",
    "\n",
    "# create \"Start-End\" string format\n",
    "# adds 10 minutes to the start time to get the end time\n",
    "final_df['interval_10min'] = (\n",
    "    interval_start.dt.strftime('%H:%M') + \"-\" + \n",
    "    (interval_start + pd.Timedelta(minutes=10)).dt.strftime('%H:%M')\n",
    ")\n",
    "\n",
    "print(final_df[['publish_time', 'interval_10min']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433809bc-5b2f-44db-b23b-c4d7927c2d4c",
   "metadata": {},
   "source": [
    "## 7. For each interval, determine the number of videos, average number of likes and of dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f949910-04dd-451f-b81b-55b6fdafa12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  interval_10min  num_videos     avg_likes  avg_dislikes\n",
      "0    00:00-00:10        2913  60951.483350   3787.232750\n",
      "1    00:10-00:20        1522  22553.870565   1437.457293\n",
      "2    00:20-00:30        1248  21258.370192   1066.330128\n",
      "3    00:30-00:40        1625  36604.352000    949.439385\n",
      "4    00:40-00:50        1283  41770.614186   1889.012471\n"
     ]
    }
   ],
   "source": [
    "interval_stats = final_df.groupby('interval_10min').agg(\n",
    "    num_videos=('video_id', 'count'),\n",
    "    avg_likes=('likes', 'mean'),\n",
    "    avg_dislikes=('dislikes', 'mean')\n",
    ").reset_index() #to reset 'interval_10min' from being index (was converted by groupby) into a flat table\n",
    "print(interval_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb132b1-9631-4f8b-b77d-274bdc575bc1",
   "metadata": {},
   "source": [
    "## 8. For each tag, determine the number of videos. Notice that tags contains a string with several tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17565839-d458-45a1-91ec-2d9d04f5a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " first 20 tags with the number of videos they repeated in:\n",
      "\n",
      "tags\n",
      "eminem                         675\n",
      "walk                           227\n",
      "on                             496\n",
      "water                          573\n",
      "aftermath/shady/interscope     127\n",
      "rap                           5476\n",
      "plush                           19\n",
      "bad unboxing                    20\n",
      "unboxing                      1385\n",
      "fan mail                        39\n",
      "idubbbztv                       42\n",
      "idubbbztv2                      33\n",
      "things                         112\n",
      "best                          2520\n",
      "packages                        13\n",
      "plushies                        22\n",
      "chontent chop                    9\n",
      "racist superman                122\n",
      "rudy                           261\n",
      "mancuso                        210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# splits and explodes tags\n",
    "tags_series = final_df['tags'].str.split('|').explode()\n",
    "\n",
    "#deleting none tags\n",
    "tags_series = tags_series.replace('', None).dropna()\n",
    "\n",
    "#remove spaces/quotation and lowercase the strings\n",
    "tags_series = tags_series.str.strip().str.strip('\"').str.lower()\n",
    "\n",
    "#number of videos for each tag\n",
    "tag_counts = tags_series.value_counts(sort=False)\n",
    "print(\"\\n first 20 tags with the number of videos they repeated in:\\n\")\n",
    "print(tag_counts.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6761b93-ed5f-491a-9f0c-8cb9d6959d7d",
   "metadata": {},
   "source": [
    "## 9. Find the tags with the largest number of videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66ad2554-20f9-4abb-b119-835db774deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags\n",
      "funny     17344\n",
      "comedy    15701\n",
      "2018      11402\n",
      "news       9199\n",
      "music      8262\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# first I decided to delete [none] tag\n",
    "tags_series_new = tags_series.replace('[none]', None).dropna()\n",
    "\n",
    "# Then to sort the tags\n",
    "tag_counts_sorted = tags_series_new.value_counts()\n",
    "\n",
    "print(tag_counts_sorted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3ff9b-fe42-40e8-8833-c6006b886fa1",
   "metadata": {},
   "source": [
    "## 10. For each (tag, country) pair, compute average ratio likes/dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a90210dd-5a6e-47c3-82d1-97a27d1ea5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tag      country  \\\n",
      "0                           ! banii i-au luat mintile      Germany   \n",
      "1                                                  !!       France   \n",
      "2                                                  !!       Mexico   \n",
      "3                                     !! *me bloquea*       Mexico   \n",
      "4                                                 !!!       Mexico   \n",
      "5                                                !!!!       France   \n",
      "6                             !00% sketch comedy show       Russia   \n",
      "7                                             !t live  South Korea   \n",
      "8                                   # carlosvideostar       Mexico   \n",
      "9   # einen sch√∂nen tag w√ºnschen# einen sch√∂nen so...      Germany   \n",
      "10                                    # ssc scam 2018        India   \n",
      "11                            # ssc scam protest 2018        India   \n",
      "12                                          # „Ç≥„É™„Ç¢„É≥„Çø„Ç¶„É≥        Japan   \n",
      "13                                          ##cutting       Russia   \n",
      "14                                        ##free view       Russia   \n",
      "15                                 ##jessi##cantora##       Russia   \n",
      "16                                                 #0       Mexico   \n",
      "17                                                #02       France   \n",
      "18                                                #03      Germany   \n",
      "19                                               #044       Mexico   \n",
      "\n",
      "    average_ratio  \n",
      "0        6.222739  \n",
      "1       12.452875  \n",
      "2       38.081559  \n",
      "3       65.260870  \n",
      "4       12.952381  \n",
      "5        5.000000  \n",
      "6             NaN  \n",
      "7      912.398601  \n",
      "8       60.160000  \n",
      "9             NaN  \n",
      "10      35.552176  \n",
      "11      35.552176  \n",
      "12       8.393258  \n",
      "13      56.714286  \n",
      "14            NaN  \n",
      "15       5.900000  \n",
      "16      69.747005  \n",
      "17      71.863309  \n",
      "18      98.460835  \n",
      "19      88.750000  \n"
     ]
    }
   ],
   "source": [
    "df_pairs = final_df[['tags', 'country', 'like_ratio']].copy()\n",
    "\n",
    "df_pairs['tags'] = df_pairs['tags'].str.split('|')\n",
    "df_pairs = df_pairs.explode('tags')\n",
    "\n",
    "# clean & split tags\n",
    "df_pairs['tags'] = df_pairs['tags'].str.strip().str.strip('\"').str.lower()\n",
    "\n",
    "\n",
    "# remove empty, [none], nan tags\n",
    "df_pairs = df_pairs.dropna(subset=['tags']) #remove real Nulls (NaN/None)\n",
    "df_pairs = df_pairs[df_pairs['tags'] != ''] #remove empty strings ('')\n",
    "df_pairs = df_pairs[df_pairs['tags'] != '[none]'] #remove the \"[none]\" tags\n",
    "\n",
    "# calculating the average of like_ratio For each (tag, country) pair \n",
    "result = df_pairs.groupby(['tags', 'country'])['like_ratio'].mean().reset_index()\n",
    "\n",
    "#to make columns by their names to have a clear output\n",
    "result.columns = ['tag', 'country', 'average_ratio']\n",
    "\n",
    "print(result.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834ad50-504d-4a83-b3e2-649aad3d3653",
   "metadata": {},
   "source": [
    "## 11. For each (trending_date, country) pair, the video with the largest number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e813c6e7-60a6-4d88-a52c-76f1316bd4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top videos per date and country:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>country</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150857</th>\n",
       "      <td>18.07.04</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...</td>\n",
       "      <td>424538912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150657</th>\n",
       "      <td>18.06.04</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...</td>\n",
       "      <td>413586699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150453</th>\n",
       "      <td>18.05.04</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...</td>\n",
       "      <td>402650804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150256</th>\n",
       "      <td>18.04.04</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...</td>\n",
       "      <td>392036878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150060</th>\n",
       "      <td>18.03.04</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...</td>\n",
       "      <td>382401497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trending_date         country  \\\n",
       "150857      18.07.04  United Kingdom   \n",
       "150657      18.06.04  United Kingdom   \n",
       "150453      18.05.04  United Kingdom   \n",
       "150256      18.04.04  United Kingdom   \n",
       "150060      18.03.04  United Kingdom   \n",
       "\n",
       "                                                    title      views  \n",
       "150857  Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...  424538912  \n",
       "150657  Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...  413586699  \n",
       "150453  Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...  402650804  \n",
       "150256  Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...  392036878  \n",
       "150060  Nicky Jam x J. Balvin - X (EQUIS) | Video Ofic...  382401497  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q11_result= final_df.loc[ final_df.groupby( ['trending_date' , 'country'])['views'].idxmax()] \n",
    "q11_result= q11_result.sort_values(by='views',ascending= False) \n",
    "\n",
    "print( \"top videos per date and country:\")\n",
    "display(q11_result[['trending_date', 'country', 'title', 'views']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae0722-9deb-41ec-bf7f-69820cb533a3",
   "metadata": {},
   "source": [
    "## 12. Divide trending_date into three columns: year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e86df2f-75bb-4f1b-b000-df2d2e560eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trending_date  year  month  day\n",
       "0    2017-11-14  2017     11   14\n",
       "1    2017-11-14  2017     11   14\n",
       "2    2017-11-14  2017     11   14\n",
       "3    2017-11-14  2017     11   14\n",
       "4    2017-11-14  2017     11   14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df[ 'trending_date'] = pd.to_datetime( final_df['trending_date'] , format='%y.%d.%m')\n",
    "\n",
    "final_df['year'] = final_df['trending_date'].dt.year\n",
    "final_df['month'] = final_df['trending_date'].dt.month\n",
    "final_df['day'] = final_df['trending_date'].dt.day\n",
    "\n",
    "print( \"columns created successfully!\")\n",
    "display(final_df[['trending_date', 'year', 'month', 'day']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e96bc-15e0-456d-884f-79827fad30bb",
   "metadata": {},
   "source": [
    "## 13. For each (month, country) pair, the video with the largest number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bd7f52a-bfdd-4645-9596-e2d6ab4c66fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top videos per month and country:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>country</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11214</th>\n",
       "      <td>1</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...</td>\n",
       "      <td>43067983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92853</th>\n",
       "      <td>1</td>\n",
       "      <td>France</td>\n",
       "      <td>Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...</td>\n",
       "      <td>37728802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51930</th>\n",
       "      <td>1</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...</td>\n",
       "      <td>37728802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173405</th>\n",
       "      <td>1</td>\n",
       "      <td>India</td>\n",
       "      <td>Taylor Swift - End Game ft. Ed Sheeran, Future</td>\n",
       "      <td>42019590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264769</th>\n",
       "      <td>1</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...</td>\n",
       "      <td>31680160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259064</th>\n",
       "      <td>12</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>YouTube Rewind: The Shape of 2017 | #YouTubeRe...</td>\n",
       "      <td>100912384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299087</th>\n",
       "      <td>12</td>\n",
       "      <td>Russia</td>\n",
       "      <td>YouTube Rewind: The Shape of 2017 | #YouTubeRe...</td>\n",
       "      <td>52611730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224092</th>\n",
       "      <td>12</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>YouTube Rewind: The Shape of 2017 | #YouTubeRe...</td>\n",
       "      <td>113876217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130634</th>\n",
       "      <td>12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>YouTube Rewind: The Shape of 2017 | #YouTubeRe...</td>\n",
       "      <td>169884583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341174</th>\n",
       "      <td>12</td>\n",
       "      <td>United States</td>\n",
       "      <td>YouTube Rewind: The Shape of 2017 | #YouTubeRe...</td>\n",
       "      <td>149376127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        month         country  \\\n",
       "11214       1          Canada   \n",
       "92853       1          France   \n",
       "51930       1         Germany   \n",
       "173405      1           India   \n",
       "264769      1          Mexico   \n",
       "...       ...             ...   \n",
       "259064     12          Mexico   \n",
       "299087     12          Russia   \n",
       "224092     12     South Korea   \n",
       "130634     12  United Kingdom   \n",
       "341174     12   United States   \n",
       "\n",
       "                                                    title      views  \n",
       "11214   Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...   43067983  \n",
       "92853   Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...   37728802  \n",
       "51930   Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...   37728802  \n",
       "173405     Taylor Swift - End Game ft. Ed Sheeran, Future   42019590  \n",
       "264769  Bruno Mars - Finesse (Remix) [Feat. Cardi B] [...   31680160  \n",
       "...                                                   ...        ...  \n",
       "259064  YouTube Rewind: The Shape of 2017 | #YouTubeRe...  100912384  \n",
       "299087  YouTube Rewind: The Shape of 2017 | #YouTubeRe...   52611730  \n",
       "224092  YouTube Rewind: The Shape of 2017 | #YouTubeRe...  113876217  \n",
       "130634  YouTube Rewind: The Shape of 2017 | #YouTubeRe...  169884583  \n",
       "341174  YouTube Rewind: The Shape of 2017 | #YouTubeRe...  149376127  \n",
       "\n",
       "[77 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we group by 'month' and 'country' ( created in q12 ), find the index of max views, and select those rows\n",
    "\n",
    "q13_result= final_df.loc[ final_df.groupby( [ 'month','country']) ['views'].idxmax()] \n",
    "#sort the result by month to make it easier to read\n",
    "q13_result= q13_result.sort_values(by=['month'])\n",
    "\n",
    "print(\"top videos per month and country:\")\n",
    "display(q13_result[['month','country','title', 'views']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb596ee2-ed56-4f91-a91c-e24dc765fcba",
   "metadata": {},
   "source": [
    "## 14. Read all json files with the video categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f88c8d8-3a12-42b0-b1bd-0f6d657b3693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded: CA\n",
      "‚úÖ Loaded: DE\n",
      "‚úÖ Loaded: FR\n",
      "‚úÖ Loaded: GB\n",
      "‚úÖ Loaded: IN\n",
      "‚úÖ Loaded: JP\n",
      "‚úÖ Loaded: KR\n",
      "‚úÖ Loaded: MX\n",
      "‚úÖ Loaded: RU\n",
      "‚úÖ Loaded: US\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "folder_path = r\"C:\\Users\\broba\\Python-Project\\trendingYT\" \n",
    "category_data = {}\n",
    "\n",
    "try:\n",
    "    all_files = os.listdir(folder_path)\n",
    "    for filename in all_files:\n",
    "        if filename.endswith('_category_id.json'):\n",
    "            country_code = filename.split('_')[0]\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                valid_ids = [int(item['id']) for item in data['items']]\n",
    "                category_data[country_code] = valid_ids\n",
    "                print(f\"‚úÖ Loaded: {country_code}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Folder not found at {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136719f-0dfd-4266-8bfe-ace3f7385b47",
   "metadata": {},
   "source": [
    "## 15. For each country, determine how many videos have a category that is not assignable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78596d7b-07bc-4c6a-bcab-f60330e7ed04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country              | Bad Categories Count\n",
      "_____________________________________________\n",
      "Canada               | 74\n",
      "Germany              | 256\n",
      "France               | 114\n",
      "United Kingdom       | 90\n",
      "India                | 105\n",
      "Japan                | 18\n",
      "South Korea          | 288\n",
      "Mexico               | 252\n",
      "Russia               | 1541\n",
      "United States        | 0\n"
     ]
    }
   ],
   "source": [
    "# --- STRATEGY EXPLANATION ---\n",
    "# The CSV file uses full country names (e.g., 'France'), while JSON filenames use 2-letter codes (e.g., 'FR').\n",
    "# 1. The dataset contains non-standard names (e.g., 'Great Britain' vs. ISO standard 'United Kingdom') which causes errors in automated libraries.\n",
    "# 2. Since the scope is limited to only 10 countries, a manual dictionary ensures 100% accuracy without adding external dependencies.\n",
    "\n",
    "country_mapper = {\n",
    "    'United States' : 'US',\n",
    "    'United Kingdom' : 'GB' ,\n",
    "    'Germany' : 'DE',\n",
    "    'Canada' : 'CA',\n",
    "    'France' : 'FR',\n",
    "    'Russia' : 'RU',\n",
    "    'Mexico' : 'MX',\n",
    "    'South Korea': 'KR',\n",
    "    'Japan' : 'JP',\n",
    "    'India' : 'IN'\n",
    "}\n",
    "\n",
    "print(f\"{'country':<20} | {'Bad Categories Count'}\") \n",
    "print(\"_\" * 45) \n",
    "\n",
    "for country_name in final_df['country'].unique():\n",
    "    country_code = country_mapper.get(country_name)\n",
    "\n",
    "    if country_code and country_code in category_data:\n",
    "        valid_ids = category_data[country_code]\n",
    "        country_df = final_df[final_df['country'] == country_name]\n",
    "        \n",
    "        bad_videos = country_df[~country_df['category_id'].isin(valid_ids)]\n",
    "        print(f\"{country_name:<20} | {len(bad_videos)}\")\n",
    "    else:\n",
    "        print(f\"{country_name:<20} | Data not found (Code: {country_code})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
