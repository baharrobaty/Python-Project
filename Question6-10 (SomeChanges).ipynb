{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6e0c8c-9182-4b22-827c-6115bf86931a",
   "metadata": {},
   "source": [
    "## Question 6 : Cluster the publish time into 10-minute intervals (e.g. from 02:20 to 02:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec14ab4a-109d-4209-898a-04272981170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id trending_date  \\\n",
      "0  n1WpP7iowLc      17.14.11   \n",
      "1  0dBIkQ4Mz1M      17.14.11   \n",
      "2  5qpjK5DgCt4      17.14.11   \n",
      "3  d380meD0W0M      17.14.11   \n",
      "4  2Vv-BfVoq4g      17.14.11   \n",
      "\n",
      "                                               title channel_title  \\\n",
      "0         Eminem - Walk On Water (Audio) ft. BeyoncÃ©    EminemVEVO   \n",
      "1                      PLUSH - Bad Unboxing Fan Mail     iDubbbzTV   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...  Rudy Mancuso   \n",
      "3                           I Dare You: GOING BALD!?      nigahiga   \n",
      "4        Ed Sheeran - Perfect (Official Music Video)    Ed Sheeran   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           10  2017-11-10T17:00:03.000Z   \n",
      "1           23  2017-11-13T17:00:00.000Z   \n",
      "2           23  2017-11-12T19:05:24.000Z   \n",
      "3           24  2017-11-12T18:01:41.000Z   \n",
      "4           10  2017-11-09T11:04:14.000Z   \n",
      "\n",
      "                                                tags     views    likes  \\\n",
      "0  Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...  17158579   787425   \n",
      "1  plush|\"bad unboxing\"|\"unboxing\"|\"fan mail\"|\"id...   1014651   127794   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...   3191434   146035   \n",
      "3  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...   2095828   132239   \n",
      "4  edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...  33523622  1634130   \n",
      "\n",
      "   dislikes  comment_count                                  thumbnail_link  \\\n",
      "0     43420         125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
      "1      1688          13030  https://i.ytimg.com/vi/0dBIkQ4Mz1M/default.jpg   \n",
      "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "4     21082          85067  https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg   \n",
      "\n",
      "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0              False             False                   False   \n",
      "1              False             False                   False   \n",
      "2              False             False                   False   \n",
      "3              False             False                   False   \n",
      "4              False             False                   False   \n",
      "\n",
      "                                         description country  like_ratio  \\\n",
      "0  Eminem's new track Walk on Water ft. BeyoncÃ© i...  Canada   18.135076   \n",
      "1  STill got a lot of packages. Probably will las...  Canada   75.707346   \n",
      "2  WATCH MY PREVIOUS VIDEO â–¶ \\n\\nSUBSCRIBE â–º http...  Canada   27.352500   \n",
      "3  I know it's been a while since we did this sho...  Canada   66.485168   \n",
      "4  ðŸŽ§: https://ad.gt/yt-perfect\\nðŸ’°: https://atlant...  Canada   77.513044   \n",
      "\n",
      "   no_dislikes  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n"
     ]
    }
   ],
   "source": [
    "#to solve this question first I need to have the solution for question 1,\n",
    "#and also for question 10 I need to have question 5 to be solved\n",
    "#so I have get the file 'final_df.csv' from my teammate.\n",
    "#because the file was larger than 100MB we could not load it in the github.\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "final_df = pd.read_csv(r'C:\\Users\\Utente\\final_df.csv')\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdc84a46-4fd7-4957-966e-e44fb4c65029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         publish_time interval_10min\n",
      "0 2017-11-10 17:00:03    17:00-17:10\n",
      "1 2017-11-13 17:00:00    17:00-17:10\n",
      "2 2017-11-12 19:05:24    19:00-19:10\n",
      "3 2017-11-12 18:01:41    18:00-18:10\n",
      "4 2017-11-09 11:04:14    11:00-11:10\n"
     ]
    }
   ],
   "source": [
    "# Convert the column to datetime objects\n",
    "final_df['publish_time'] = pd.to_datetime(final_df['publish_time'])\n",
    "\n",
    "# remove the timezone (I checked it in the file, it was the same in all countries)\n",
    "final_df['publish_time'] = final_df['publish_time'].dt.tz_localize(None)\n",
    "\n",
    "# round down to the nearest 10 minutes. Example: 02:23:00 becomes 02:20:00\n",
    "interval_start = final_df['publish_time'].dt.floor('10min')\n",
    "\n",
    "# create \"Start-End\" string format\n",
    "# adds 10 minutes to the start time to get the end time\n",
    "final_df['interval_10min'] = (\n",
    "    interval_start.dt.strftime('%H:%M') + \"-\" + \n",
    "    (interval_start + pd.Timedelta(minutes=10)).dt.strftime('%H:%M')\n",
    ")\n",
    "\n",
    "print(final_df[['publish_time', 'interval_10min']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00218cd7-fc35-458d-990a-b6d44365fdc8",
   "metadata": {},
   "source": [
    "## Question 7 : For each interval, determine the number of videos, average number of likes and of dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d23e7430-4e94-407a-b330-83800898eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  interval_10min  num_videos     avg_likes  avg_dislikes\n",
      "0    00:00-00:10        2913  60951.483350   3787.232750\n",
      "1    00:10-00:20        1522  22553.870565   1437.457293\n",
      "2    00:20-00:30        1248  21258.370192   1066.330128\n",
      "3    00:30-00:40        1625  36604.352000    949.439385\n",
      "4    00:40-00:50        1283  41770.614186   1889.012471\n"
     ]
    }
   ],
   "source": [
    "interval_stats = final_df.groupby('interval_10min').agg(\n",
    "    num_videos=('video_id', 'count'),\n",
    "    avg_likes=('likes', 'mean'),\n",
    "    avg_dislikes=('dislikes', 'mean')\n",
    ").reset_index() #to reset 'interval_10min' from being index (was converted by groupby) into a flat table\n",
    "print(interval_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea31b09-ec69-4f9b-a11e-a14966d7541e",
   "metadata": {},
   "source": [
    "## Question 8 : For each tag, determine the number of videos. Notice that tags contains a string with several tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c64d156-784a-433f-b47e-7069104901fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " first 20 tags with the number of videos they repeated in:\n",
      "\n",
      "tags\n",
      "eminem                         675\n",
      "walk                           227\n",
      "on                             496\n",
      "water                          573\n",
      "aftermath/shady/interscope     127\n",
      "rap                           5476\n",
      "plush                           19\n",
      "bad unboxing                    20\n",
      "unboxing                      1385\n",
      "fan mail                        39\n",
      "idubbbztv                       42\n",
      "idubbbztv2                      33\n",
      "things                         112\n",
      "best                          2520\n",
      "packages                        13\n",
      "plushies                        22\n",
      "chontent chop                    9\n",
      "racist superman                122\n",
      "rudy                           261\n",
      "mancuso                        210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# splits and explodes tags\n",
    "tags_series = final_df['tags'].str.split('|').explode()\n",
    "\n",
    "#deleting none tags\n",
    "tags_series = tags_series.replace('', None).dropna()\n",
    "\n",
    "#remove spaces/quotation and lowercase the strings\n",
    "tags_series = tags_series.str.strip().str.strip('\"').str.lower()\n",
    "\n",
    "#number of videos for each tag\n",
    "tag_counts = tags_series.value_counts(sort=False)\n",
    "print(\"\\n first 20 tags with the number of videos they repeated in:\\n\")\n",
    "print(tag_counts.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada610d-e1de-44ff-b281-02c99f437d1c",
   "metadata": {},
   "source": [
    "## Question 9 : Find the tags with the largest number of videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8f384af-fb6a-40ca-8b8a-5a0146970198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags\n",
      "funny     17344\n",
      "comedy    15701\n",
      "2018      11402\n",
      "news       9199\n",
      "music      8262\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# first I decided to delete [none] tag\n",
    "tags_series_new = tags_series.replace('[none]', None).dropna()\n",
    "\n",
    "# Then to sort the tags\n",
    "tag_counts_sorted = tags_series_new.value_counts()\n",
    "\n",
    "print(tag_counts_sorted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105acc79-08e8-402c-938f-54ad7f13917f",
   "metadata": {},
   "source": [
    "## Question 10 : For each (tag, country) pair, compute average ratio likes/dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2487dd50-566b-4e79-8cae-a554b70a46fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tag      country  \\\n",
      "0                           ! banii i-au luat mintile      Germany   \n",
      "1                                                  !!       France   \n",
      "2                                                  !!       Mexico   \n",
      "3                                     !! *me bloquea*       Mexico   \n",
      "4                                                 !!!       Mexico   \n",
      "5                                                !!!!       France   \n",
      "6                             !00% sketch comedy show       Russia   \n",
      "7                                             !t live  South Korea   \n",
      "8                                   # carlosvideostar       Mexico   \n",
      "9   # einen schÃ¶nen tag wÃ¼nschen# einen schÃ¶nen so...      Germany   \n",
      "10                                    # ssc scam 2018        India   \n",
      "11                            # ssc scam protest 2018        India   \n",
      "12                                          # ã‚³ãƒªã‚¢ãƒ³ã‚¿ã‚¦ãƒ³        Japan   \n",
      "13                                          ##cutting       Russia   \n",
      "14                                        ##free view       Russia   \n",
      "15                                 ##jessi##cantora##       Russia   \n",
      "16                                                 #0       Mexico   \n",
      "17                                                #02       France   \n",
      "18                                                #03      Germany   \n",
      "19                                               #044       Mexico   \n",
      "\n",
      "    average_ratio  \n",
      "0        6.222739  \n",
      "1       12.452875  \n",
      "2       38.081559  \n",
      "3       65.260870  \n",
      "4       12.952381  \n",
      "5        5.000000  \n",
      "6             NaN  \n",
      "7      912.398601  \n",
      "8       60.160000  \n",
      "9             NaN  \n",
      "10      35.552176  \n",
      "11      35.552176  \n",
      "12       8.393258  \n",
      "13      56.714286  \n",
      "14            NaN  \n",
      "15       5.900000  \n",
      "16      69.747005  \n",
      "17      71.863309  \n",
      "18      98.460835  \n",
      "19      88.750000  \n"
     ]
    }
   ],
   "source": [
    "df_pairs = final_df[['tags', 'country', 'like_ratio']].copy()\n",
    "\n",
    "df_pairs['tags'] = df_pairs['tags'].str.split('|')\n",
    "df_pairs = df_pairs.explode('tags')\n",
    "\n",
    "# clean & split tags\n",
    "df_pairs['tags'] = df_pairs['tags'].str.strip().str.strip('\"').str.lower()\n",
    "\n",
    "\n",
    "# remove empty, [none], nan tags\n",
    "df_pairs = df_pairs.dropna(subset=['tags']) #remove real Nulls (NaN/None)\n",
    "df_pairs = df_pairs[df_pairs['tags'] != ''] #remove empty strings ('')\n",
    "df_pairs = df_pairs[df_pairs['tags'] != '[none]'] #remove the \"[none]\" tags\n",
    "\n",
    "# calculating the average of like_ratio For each (tag, country) pair \n",
    "result = df_pairs.groupby(['tags', 'country'])['like_ratio'].mean().reset_index()\n",
    "\n",
    "#to make columns by their names to have a clear output\n",
    "result.columns = ['tag', 'country', 'average_ratio']\n",
    "\n",
    "print(result.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
